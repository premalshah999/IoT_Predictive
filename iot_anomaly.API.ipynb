{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT Anomaly Detection API - Usage Demo\n",
    "\n",
    "This notebook demonstrates the usage of the `IoTAnomalyDetector` API for anomaly detection in smart manufacturing.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The API provides a high-level interface for:\n",
    "- Loading and preprocessing IoT sensor data\n",
    "- Feature engineering (67 features from 5 sensors)\n",
    "- Training and evaluating ML models\n",
    "- Making predictions on new data\n",
    "- Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iot_anomaly_utils import IoTAnomalyDetector\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector instance\n",
    "detector = IoTAnomalyDetector()\n",
    "print(\"IoTAnomalyDetector initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Data\n",
    "\n",
    "Load a sample of the IoT sensor data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 1000 samples for quick demonstration\n",
    "detector.load_data(\"data/smart_manufacturing_data.csv\", sample_size=1000)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Raw data shape: {detector.df_raw.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "detector.df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Features\n",
    "\n",
    "Generate 67 engineered features from the 5 raw sensor readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for anomaly detection task\n",
    "detector.prepare_features(\"anomaly_flag\")\n",
    "\n",
    "print(f\"Engineered features shape: {detector.df_features.shape}\")\n",
    "print(f\"\\nFeature columns (first 20):\")\n",
    "print(list(detector.df_features.columns[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Data\n",
    "\n",
    "Split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train-test split\n",
    "X_train, X_test, y_train, y_test = detector.prepare_train_test_split(\n",
    "    target_col=\"anomaly_flag\",\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Pre-Trained Model\n",
    "\n",
    "Load the best anomaly detection model trained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best anomaly detection model\n",
    "detector.load_model(\"models/best_anomaly_model.pkl\")\n",
    "print(f\"Loaded model: {type(detector.model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "predictions = detector.predict(X_test)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"\\nPredictions distribution:\")\n",
    "print(pd.Series(predictions).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics = detector.evaluate_classification(y_test, predictions)\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results\n",
    "\n",
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "fig = detector.plot_confusion_matrix(y_test, predictions)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 20 most important features\n",
    "fig = detector.plot_feature_importance(top_n=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Other Models\n",
    "\n",
    "### Maintenance Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data for maintenance prediction\n",
    "detector.load_data(\"data/smart_manufacturing_data.csv\", sample_size=1000)\n",
    "detector.prepare_features(\"maintenance_required\")\n",
    "X_train, X_test, y_train, y_test = detector.prepare_train_test_split(\n",
    "    target_col=\"maintenance_required\"\n",
    ")\n",
    "\n",
    "# Load maintenance model\n",
    "detector.load_model(\"models/best_maintenance_model.pkl\")\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = detector.predict(X_test)\n",
    "metrics = detector.evaluate_classification(y_test, predictions)\n",
    "\n",
    "print(\"\\nMaintenance Prediction Performance:\")\n",
    "print(f\"  F1 Score: {metrics['f1']:.4f}\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downtime Risk Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data for downtime prediction\n",
    "detector.load_data(\"data/smart_manufacturing_data.csv\", sample_size=1000)\n",
    "detector.prepare_features(\"downtime_risk\")\n",
    "X_train, X_test, y_train, y_test = detector.prepare_train_test_split(\n",
    "    target_col=\"downtime_risk\"\n",
    ")\n",
    "\n",
    "# Load downtime model\n",
    "detector.load_model(\"models/best_downtime_model.pkl\")\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = detector.predict(X_test)\n",
    "metrics = detector.evaluate_classification(y_test, predictions)\n",
    "\n",
    "print(\"\\nDowntime Risk Prediction Performance:\")\n",
    "print(f\"  F1 Score: {metrics['f1']:.4f}\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quick Prediction Function\n",
    "\n",
    "Use the convenience function for quick predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iot_anomaly_utils import quick_predict\n",
    "\n",
    "# Quick prediction on sample data\n",
    "predictions = quick_predict(\n",
    "    data_path=\"data/smart_manufacturing_data.csv\",\n",
    "    model_path=\"models/best_anomaly_model.pkl\",\n",
    "    target_col=\"anomaly_flag\",\n",
    "    sample_size=500\n",
    ")\n",
    "\n",
    "print(f\"Quick predictions: {predictions[:10]}\")\n",
    "print(f\"Anomaly rate: {predictions.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading the IoTAnomalyDetector API\n",
    "2. Loading and preprocessing IoT sensor data\n",
    "3. Feature engineering (67 features)\n",
    "4. Loading pre-trained models\n",
    "5. Making predictions\n",
    "6. Evaluating performance\n",
    "7. Visualizing results\n",
    "8. Testing multiple models (anomaly, maintenance, downtime)\n",
    "\n",
    "**Key Results:**\n",
    "- Anomaly Detection: 99.98% F1 Score\n",
    "- Maintenance Prediction: 98.21% F1 Score\n",
    "- Downtime Risk: 99.98% F1 Score\n",
    "\n",
    "For more examples, see [iot_anomaly.example.ipynb](iot_anomaly.example.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
